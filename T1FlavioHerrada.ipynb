{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d1867ad",
   "metadata": {},
   "source": [
    "# MLOps\n",
    "\n",
    "Los MLOps se trata de una serie de pasos y cosas que se hacen para mandar un modelo de ML a la onda de producción. Hay varios pasos que deben llevarse a cabo antes de que un ML esté listo para producción. Estos procesos aseguran que tu modelo pueda ser escalado para una gran cantidad de usuarios y SOBRE TODO que funcione muy bien para su uso.\n",
    "\n",
    "Hacer un modelo de ML que pueda adivinar lo que quieras a partir de los datos que le metes, fácil. Pero armar un modelo de ML que sea confiable, rápido, preciso y que pueda usar un montón de personas, ahí sí se pone tricky.\n",
    "\n",
    "Y los siguientes son algunos ejemplos que nos dicen el por qué necesitamos necesitamos los MLOps:\n",
    "\n",
    "- Los modelos de ML se apoyan en un montón de datos, imposible para una sola persona llevarles el ritmo.\n",
    "+ Es complicado seguirle la pista a los ajustes que le hacemos a los modelos de ML, cambios mínimos pueden significar resultados mega diferentes.\n",
    "+ Tenemos que estar al pendiente de las características con las que trabaja el modelo.\n",
    "+ Resolver problemas en un modelo de ML es un arte muy complicado.\n",
    "+ Los modelos dependen de datos del mundo real para predecir cosas, y como esos datos cambian, el modelo también tiene que cambiar. O sea, hay que estar al tanto de los cambios en los datos nuevos y asegurarnos de que el modelo aprenda de acuerdo a eso.\n",
    "\n",
    "Como MLOps es una serie de pasos, pues aqui están los pasos:\n",
    "\n",
    "1. *Delimitación*, donde armamos el plan, checamos si el problema se resuelve con ML. Revizamos qué datos necesitamos y si están en el rollo correcto. Además, checamos si los datos son imparciales y si reflejan cómo se usarían en la vida real.\n",
    "\n",
    "2. Luego viene la *Ingeniería de Datos*, que es agarrar los datos, poner puntos de referencia, limpiarlos, ordenarlos y etiquetarlos. O sea, los dejamos ready para el show.\n",
    "\n",
    "3. Después entra en acción el *Modelado*. Aquí nos ponemos las pilas con la programación y armamos el modelo de ML con los datos procesados. También analizamos los errores, definimos cómo medirlos y vemos qué tan bien lo está haciendo el modelo.\n",
    "\n",
    "4. Luego está el *Despliegue*. En esta parte empacamos el modelo y lo ponemos a correr en la nube o en dispositivos locales, según cómo se necesite. Puede ser como envolver el modelo en un servidor de API que se conecta con puntos finales, o en un contenedor Docker que vuela en la nube, o hasta en una app móvil para cuando es algo local.\n",
    "\n",
    "5. Y finalmente, tenemos la onda de *Monitorización*. Una vez que está todo en marcha, necesitamos un sistema para vigilar el modelo. Esto incluye estar pendientes de la infraestructura en la que está funcionando, y también checar cómo se está portando el modelo en términos de rendimiento, precisión, fallos, chamba rara y cambios en los datos. Así nos aseguramos de que esté dando la talla en el mundo real.\n",
    "\n",
    "Este es el ciclo de vida de MLOps y nunca acaba. La primera vez que hacemos este proceso se le conoce como *nivel 0* y es por simple hecho de que creamos nuestro modelo manualmente, pero si le programamos una *automation pipeline* que es la misma serie de tareas que normalmente requerirían intervención humana y se automatiza para que se ejecuten de manera sistemática y repetible, esta automatización se le conoce como *nivel 1*.\n",
    "\n",
    "Rara vez se llega al *nivel 2*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bead448f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
